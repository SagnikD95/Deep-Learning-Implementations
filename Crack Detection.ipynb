{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sunset-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import glob\n",
    "import os\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x000001FA47190F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x000001FA47190F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x000001FA47190F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "#Pre trained MobineNet V2 from TfHub\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier_model =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bearing-leisure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1001)              3540265   \n",
      "=================================================================\n",
      "Total params: 3,540,265\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "apparent-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.//data//train//', ['cracked', 'uncracked'], [])\n",
      ".//data//train//uncracked//*\n",
      ".//data//train//cracked//*\n",
      "(37369, 256, 256, 3) (37369, 1) (2000, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "def augment(img):\n",
    "    img1 = np.fliplr(img)\n",
    "    img2 = np.flipud(img)\n",
    "    img3 = ndimage.rotate(img,45,reshape=False)\n",
    "    return img1,img2,img3\n",
    "def load_image(path):\n",
    "    #dim =  (299,299)\n",
    "    img = cv2.imread(path)\n",
    "    norm_img = np.zeros((256,256))\n",
    "    img = cv2.normalize(img,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "    #img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    #processedimage = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "#Load Crack Test Data\n",
    "def load_data_test(path):\n",
    "    x = []\n",
    "    files =glob.glob(path)\n",
    "    #print(files)\n",
    "    for file in files:\n",
    "        x.append(load_image(file))\n",
    "    x=np.array(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "#Load Crack Train Data\n",
    "def load_data(path):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    c = 0\n",
    "    dirname, f, filenames= os.walk(path)\n",
    "    print(dirname)\n",
    "    cracked = dirname[1][0]\n",
    "    uncracked = dirname[1][1]\n",
    "        \n",
    "    #print(uncracked)\n",
    "    #print(cracked)\n",
    "        \n",
    "    cracked = os.path.join(path,cracked)+\"//*\"\n",
    "    uncracked = os.path.join(path,uncracked)+\"//*\"\n",
    "    cracked_files = glob.glob(cracked)\n",
    "    uncracked_files = glob.glob(uncracked)\n",
    "        \n",
    "    print(uncracked)\n",
    "    print(cracked)\n",
    "    \n",
    "    for file in cracked_files:\n",
    "        x.append(load_image(file))\n",
    "        y.append(1)\n",
    "            \n",
    "    \n",
    "    for file in uncracked_files:\n",
    "        img = load_image(file)\n",
    "        img1,img2,img3 = augment(img)\n",
    "        x.append(img)\n",
    "        x.append(img1)\n",
    "        x.append(img2)\n",
    "        x.append(img3)\n",
    "        y.append(0)\n",
    "        y.append(0)\n",
    "        y.append(0)\n",
    "        y.append(0)\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.expand_dims(np.array(y),1)\n",
    "    return x,y\n",
    "\n",
    "path_train = \".//data//train//\"\n",
    "path_test = \".//data//test//*\"\n",
    "\n",
    "train_x,train_y = load_data(path_train)\n",
    "test_x = load_data_test(path_test)\n",
    "\n",
    "print(train_x.shape,train_y.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "optional-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "train_x,train_y = shuffle(train_x,train_y, random_state=0)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dynamic-attitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 65538     \n",
      "=================================================================\n",
      "Total params: 14,780,226\n",
      "Trainable params: 14,780,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Feature Extractor Headless Model from TFHUB\n",
    "\n",
    "#feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "#feature_extractor_model = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/4\"\n",
    "#feature_extractor_model = \"https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4\"\n",
    "#feature_extractor_layer = hub.KerasLayer(\n",
    "    #feature_extractor_model, input_shape=(256, 256, 3), trainable=False)\n",
    "\n",
    "feature_extractor =  tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',input_shape=(256,256,3))\n",
    "feature_extractor.summary()\n",
    "#Num of classes to Transfer Learn on\n",
    "num_classes = 2\n",
    "\n",
    "#Add Dense last layer for classification for TL\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,tf.keras.layers.Dropout(.3),tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1017/1051 [============================>.] - ETA: 4:41 - loss: 0.5648 - acc: 0.7812"
     ]
    }
   ],
   "source": [
    "#Compiling the New Model\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(.001),\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "#Callbacks\n",
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "#Train the model\n",
    "history = model.fit(train_x,tf.keras.utils.to_categorical(\n",
    "    train_y, num_classes=2, dtype='float32'),validation_data=(val_x,tf.keras.utils.to_categorical(\n",
    "    val_y, num_classes=2, dtype='float32')),batch_size = 32, epochs=30,\n",
    "                    callbacks=[batch_stats_callback])\n",
    "\n",
    "#Plotting Loss based on Callbacks\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-lighting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
